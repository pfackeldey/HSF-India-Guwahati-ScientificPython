{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a084de",
   "metadata": {},
   "source": [
    "# Lesson 5: Distributed Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7258bcf",
   "metadata": {},
   "source": [
    "In lesson 4 you've learned how to be as efficient as possible on a single CPU.\n",
    "\n",
    "Now we want to use multiple CPUs at the same time (horizontal scaling) and optimize efficiency of multiple CPUs.\n",
    "\n",
    "![image](https://raw.githubusercontent.com/nsmith-/2025-09-15-hsf-india-tutorial-chandigarh/cda03896f0f7d4d195db3fedf00a8754f6774214/img/horizontal-and-vertical-scaling.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93c286",
   "metadata": {},
   "source": [
    "## Scaling on a single machine\n",
    "\n",
    "A single computer may have multiple cores available that we can use to concurrently run software.\n",
    "\n",
    "#### In python the two ways to parallelize programs are: **_multi-processing_** and **_multi-threading_**.\n",
    "\n",
    "**Multi-processing** is essentially about running multiple OS processes in parallel, each with its own Python interpreter, memory space, etc.\n",
    "\n",
    "**Multi-threading**, however, uses a shared memory space and a common Python interpreter to spawn multiple threads that can run tasks concurrently. \n",
    "_Caution_: In Python multi-threading is in fact not running programs in parallel because of the Global Interpreter Lock (GIL), only since python 3.14 (free-threaded) this is possible.\n",
    "\n",
    "\n",
    "### Basic rule of thumb for Python:\n",
    "\n",
    "**Use multi-processing** when you're program is CPU-bound (i.e. it's constantly calculating things).\n",
    "\n",
    "**Use multi-threading** when you're program is IO-bound (i.e. it's waiting a long time for loading data or network requests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00df883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23144dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting quadratic_formula_scaling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile quadratic_formula_scaling.py\n",
    "# writing to a separate file, because multiprocessing is buggy in notebooks (see: https://bugs.python.org/issue25053)\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "a = np.random.uniform(5, 10, 1_000_000)\n",
    "b = np.random.uniform(10, 20, 1_000_000)\n",
    "c = np.random.uniform(-0.1, 0.1, 1_000_000)\n",
    "\n",
    "def quadratic_formula(task_id):\n",
    "    time.sleep(task_id / 5.0)  # simulate some task_id-dependent workload\n",
    "    return (-b + np.sqrt(b**2 - 4*a*c)), task_id  # return task_id for identification\n",
    "\n",
    "\n",
    "# setup 10 tasks\n",
    "task_ids = range(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb41807d",
   "metadata": {},
   "source": [
    "### Python for-loop example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5900ce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 1 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 2 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 3 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 4 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 5 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 6 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 7 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 8 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 9 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "9.21 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "from quadratic_formula_scaling import quadratic_formula, task_ids\n",
    "\n",
    "for task_id in task_ids:\n",
    "    output, _ = quadratic_formula(task_id)\n",
    "    print(f\"Task {task_id} completed with output {output[:5]}...\")  # print first 5 results of each task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f8291",
   "metadata": {},
   "source": [
    "### Multi-threading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df0f435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 5 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 8 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 7 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 1 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 2 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 4 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 6 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 3 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "Task 9 completed with output [-0.03423688  0.0506     -0.07397691 -0.04395879 -0.0492483 ]...\n",
      "1.81 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "from quadratic_formula_scaling import quadratic_formula, task_ids\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(quadratic_formula, task_id) for task_id in task_ids]\n",
    "\n",
    "for future in concurrent.futures.as_completed(futures):\n",
    "    output, task_id = future.result()\n",
    "    print(f\"Task {task_id} completed with output {output[:5]}...\")  # print first 5 results of each task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db262c7b",
   "metadata": {},
   "source": [
    "### Multi-processing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4f34a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 9 completed with output [-0.01850971  0.05290874  0.05529105 -0.01086886  0.14588338]...\n",
      "Task 7 completed with output [-0.06165524  0.01516968 -0.09811029  0.03078042 -0.04925104]...\n",
      "Task 1 completed with output [ 0.12665125 -0.0743113  -0.09411886  0.01897715  0.01112827]...\n",
      "Task 3 completed with output [ 0.10597648  0.0145213  -0.02716122 -0.07412861 -0.06141234]...\n",
      "Task 5 completed with output [-0.09945009  0.08043627  0.00639675 -0.01837581  0.09017917]...\n",
      "Task 0 completed with output [ 0.07409236  0.00600725 -0.04949217  0.00908     0.1003149 ]...\n",
      "Task 2 completed with output [0.11341482 0.02816544 0.06614238 0.01770748 0.06747025]...\n",
      "Task 6 completed with output [ 0.06449472  0.00216018 -0.03168948 -0.06154289 -0.07528261]...\n",
      "Task 4 completed with output [ 0.06906914 -0.0009371   0.05279456  0.06236099 -0.09148618]...\n",
      "Task 8 completed with output [ 0.00633929 -0.03936166  0.02405769  0.06793498  0.04995134]...\n",
      "2.09 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "from quadratic_formula_scaling import quadratic_formula, task_ids\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(quadratic_formula, task_id) for task_id in task_ids]\n",
    "\n",
    "for future in concurrent.futures.as_completed(futures):\n",
    "    output, task_id = future.result()\n",
    "    print(f\"Task {task_id} completed with output {output[:5]}...\")  # print first 5 results of each task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c90c0",
   "metadata": {},
   "source": [
    "Multi-threading and multi-processing can speed-up your programs by concurrently executing multiple tasks across multiple threads or processes.\n",
    "\n",
    "Here, we can see in addition the effect of shared (**multi-threading**) vs individual (**multi-processing**) memory space: \n",
    "- **multi-threading**: the NumPy random initialization runs _once_ and the memory is shared between all threads, which is why all outputs are the _same_ (`[ 0.00466771  0.00414385  0.00415603 -0.00520032 -0.00212164]...`)\n",
    "- **multi-processing**: the NumPy random initialization runs in _each_ process again. There's no shared memory, every process has it's own set of `a`, `b`, and `c` arrays, which is why all outputs are _different_. Initializing the arrays in each process adds an additional runtime overhead, which is why here the multi-processing case is slightly slower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ff925",
   "metadata": {},
   "source": [
    "## Scaling on multiple machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa8625",
   "metadata": {},
   "source": [
    "## Dask\n",
    "\n",
    "There are different ways to scale to multiple machines in a computing cluster. \n",
    "\n",
    "The most classic ways are independent of Python and let you submit any type of program 'job' to a cluster, e.g. using HTCondor or Slurm.\n",
    "\n",
    "In Python, one solution emerged that allows to submit jobs/tasks to a cluster of workers from a Python program: **Dask**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac95b74",
   "metadata": {},
   "source": [
    "### Dask example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322e502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.distributed\n",
    "\n",
    "from quadratic_formula_scaling import quadratic_formula, task_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31da01f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 1 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 2 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 3 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 4 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 5 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 6 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 7 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 8 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "Task 9 completed with output [ 0.04766715 -0.03581469 -0.02952755  0.02982136  0.09562612]...\n",
      "2.62 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "with (\n",
    "    # multi-threading cluster\n",
    "    dask.distributed.LocalCluster(n_workers=1, threads_per_worker=10) as cluster,\n",
    "    # multi-processing cluster\n",
    "    # dask.distributed.LocalCluster(n_workers=10, threads_per_worker=1) as cluster,\n",
    "    # mixed cluster\n",
    "    # dask.distributed.LocalCluster(n_workers=2, threads_per_worker=5) as cluster,\n",
    "    # ---\n",
    "    # connect to a Dask cluster\n",
    "    dask.distributed.Client(cluster) as client,\n",
    "):\n",
    "    futures = client.map(quadratic_formula, task_ids)\n",
    "\n",
    "    for future in dask.distributed.as_completed(futures):\n",
    "        output, task_id = future.result()\n",
    "        print(f\"Task {task_id} completed with output {output[:5]}...\")  # print first 5 results of each task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c011d",
   "metadata": {},
   "source": [
    "### Dask in practice\n",
    "\n",
    "Dask abstracts the cluster from the user. If there's a dask-scheduler running somewhere, we can connect to it using:\n",
    "\n",
    "```python\n",
    "with dask.distributed.Client(address='127.0.0.1:8786') as client: # some IP+port address\n",
    "    ...\n",
    "```\n",
    "\n",
    "This is great, as scientist never have to worry about the cluster infrastructure, with a single lince of code you can connect and run your analysis distributed on multiple workers and optionally using multiple threads per worker.\n",
    "\n",
    "One cluster in HEP that's commonly used for analysis is: https://coffea.casa/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4398f8",
   "metadata": {},
   "source": [
    "### Dask is much more than a distributive interface\n",
    "\n",
    "Dask allows to define compute graphs of complex workflows. These graphs can then be scheduled automatically by the dask-scheduler such that the most optimal execution of tasks is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9544287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9894cd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There is no layout engine support for \"dot\"\n",
      "Perhaps \"dot -c\" needs to be run (with installer's privileges) to register the plugins?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 15\n"
     ]
    }
   ],
   "source": [
    "@dask.delayed  # mark function as delayed/task\n",
    "def increment(i):\n",
    "    return i + 1\n",
    "\n",
    "@dask.delayed  # mark function as delayed/task\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# define compute graph\n",
    "a, b = 1, 12\n",
    "c = increment(a)\n",
    "d = increment(b)\n",
    "output = add(c, d)\n",
    "\n",
    "# visualize compute graph\n",
    "try:\n",
    "    output.visualize(rankdir=\"LR\", filename=\"img/compute_graph_simple.svg\")  # left to right\n",
    "except Exception as e:\n",
    "    ... # install graphviz and python-graphviz to visualize the graph\n",
    "\n",
    "# compute the result\n",
    "print(\"Result:\", output.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ddf3a",
   "metadata": {},
   "source": [
    "![image](img/compute_graph_simple.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a6328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There is no layout engine support for \"dot\"\n",
      "Perhaps \"dot -c\" needs to be run (with installer's privileges) to register the plugins?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result (unoptimized): [-0.00575828 -0.00599738  0.00358227 ... -0.0017056   0.00664479\n",
      " -0.00026088]\n",
      "Result (optimized): [-0.00575828 -0.00599738  0.00358227 ... -0.0017056   0.00664479\n",
      " -0.00026088]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "# use dask arrays instead of Numpy arrays for automatic graph construction\n",
    "a = da.random.uniform(5, 10, 100_000)\n",
    "b = da.random.uniform(10, 20, 100_000)\n",
    "c = da.random.uniform(-0.1, 0.1, 100_000)\n",
    "\n",
    "def quadratic_formula(a, b, c):\n",
    "    return (-b + np.sqrt(b**2 - 4*a*c)) / (2*a)\n",
    "\n",
    "# define compute graph\n",
    "output = quadratic_formula(a, b, c)\n",
    "\n",
    "# visualize compute graph\n",
    "try:\n",
    "    output.visualize(rankdir=\"LR\", filename=\"img/compute_graph_quadratic_formula.svg\")\n",
    "    output.visualize(rankdir=\"LR\", filename=\"img/compute_graph_quadratic_formula__optimized.svg\", optimize_graph=True)\n",
    "except Exception as e:\n",
    "    ... # install graphviz and python-graphviz to visualize the graph\n",
    "\n",
    "\n",
    "# compute the result\n",
    "unoptimized_result = dask.compute(output, optimize_graph=False)[0]\n",
    "print(\"Result (unoptimized):\", unoptimized_result)\n",
    "\n",
    "optimized_result = dask.compute(output, optimize_graph=True)[0]\n",
    "print(\"Result (optimized):\", optimized_result)\n",
    "\n",
    "assert np.allclose(unoptimized_result, optimized_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b2e5a",
   "metadata": {},
   "source": [
    "#### Compute Graph\n",
    "\n",
    "![image](img/compute_graph_quadratic_formula.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dd392",
   "metadata": {},
   "source": [
    "#### Compute Graph _optimized_\n",
    "\n",
    "![image](img/compute_graph_quadratic_formula__optimized.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eae3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(a, b, c):\n",
    "    return np.mean((-b + np.sqrt(b**2 - 4*a*c)) / (2*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f415bc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: -9.400685890981767e-06\n",
      "5.82 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "a = np.random.uniform(5, 10, 200_000_000)\n",
    "b = np.random.uniform(10, 20, 200_000_000)\n",
    "c = np.random.uniform(-0.1, 0.1, 200_000_000)\n",
    "\n",
    "output = fun(a, b, c)\n",
    "print(\"Result:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c624b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HighLevelGraph with 15 layers.\n",
      "<dask.highlevelgraph.HighLevelGraph object at 0x16541b530>\n",
      " 0. uniform-1e36026363dbc22f77b3732cf25a6949\n",
      " 1. uniform-4d50f75559d799045ca46bfb83ab1510\n",
      " 2. mul-7d7fa4d62baa037e6709580418ce1fc4\n",
      " 3. mul-58d345cc3e88bd2084125dc92a605870\n",
      " 4. mul-8d830592cff76a4198933e4a29250e26\n",
      " 5. uniform-0acabcbdd9bedee7bf2458a4f535e061\n",
      " 6. pow-b1f20748c9e1f7bbf9ccd6f9cec95b7a\n",
      " 7. sub-70ff91ddd6b30da11501c2da556c6458\n",
      " 8. sqrt-4f14dece71960fbb80641cfc437af595\n",
      " 9. neg-8efce5b4394260aef1d32659776912ae\n",
      " 10. add-7e5d907e2fd2f3e7cc6c47f3981e79f8\n",
      " 11. truediv-1edafdc38f4b52c316fed5b93236e4d2\n",
      " 12. mean_chunk-cad526579e80bd82b6d793c90b77fff3\n",
      " 13. mean_combine-partial-11e1918753e621f51196f93132afd08b\n",
      " 14. mean_agg-aggregate-4c622a75daac39295ecd232bcdf70137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A too slow problem for a single machine... (200M points)\n",
    "\n",
    "# use dask arrays instead of Numpy arrays for automatic graph construction\n",
    "da_a = da.random.uniform(5, 10, 200_000_000)\n",
    "da_b = da.random.uniform(10, 20, 200_000_000)\n",
    "da_c = da.random.uniform(-0.1, 0.1, 200_000_000)\n",
    "\n",
    "# define compute graph\n",
    "output = fun(da_a, da_b, da_c)\n",
    "\n",
    "print(output.dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f978677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: -9.353751629793007e-06\n",
      "1.55 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "with (\n",
    "    dask.distributed.LocalCluster(n_workers=1, threads_per_worker=10) as cluster,\n",
    "    # ---\n",
    "    # connect to a Dask cluster\n",
    "    dask.distributed.Client(cluster) as client,\n",
    "):\n",
    "    # compute the result\n",
    "    print(\"Result:\", client.compute(output).result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
